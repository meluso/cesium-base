#!/bin/bash

#-------------------  Begin SLURM preamble  -------------------------#
#SBATCH --job-name=cesium_append_execset001
#SBATCH --partition=short
#SBATCH --ntasks=1
#SBATCH --mem-per-cpu=4gb
#SBATCH --time=0-03:00:00
#SBATCH --mail-type=ALL
#SBATCH --output=/gpfs1/home/j/m/%u/cesium/logs/sets/%x_%j.log
#-------------------   End SLURM preamble   -------------------------#

# Specify data directory
JOBDIR=/gpfs2/scratch/jmeluso/cesium/data

# Move to model directory
cd /gpfs1/home/j/m/jmeluso/cesium/model

# Echo some useful and interesting information
echo "  running host:    ${SLURMD_NODENAME}"
echo "  assigned nodes:  ${SLURM_JOB_NODELIST}"
echo "  partition used:  ${SLURM_JOB_PARTITION}"
echo "  jobid:           ${SLURM_JOBID}"
echo ""

# Load python module
spack load python@3.7.7
spack load py-numpy@1.18.4

# Combine data from executions 1-9
python get_data.py $JOBDIR


# to submit 100 jobs, call the file submit_loop.sh
# to run live, use the following command:
#   srun --partition=bluemoon --ntasks=1 --mem=4G --time=4:00:00 --pty /bin/bash